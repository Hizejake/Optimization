{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization (PSO) Project Report\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Particle Swarm Optimization (PSO) is a computational method used for optimizing a problem by iteratively improving a candidate solution with regard to a given measure of quality. This project explores three different implementations of the PSO algorithm and compares their performance.\n",
    "\n",
    "## Rastrigin Function\n",
    "\n",
    "The Rastrigin function is a non-convex function used as a performance test problem for optimization algorithms. It is highly multimodal, meaning it has a large number of local minima. The function is defined by:\n",
    "\n",
    "$$f(x) = An + \\sum_{i=1}^{n} \\left[ x_i^2 - A \\cos(2\\pi x_i) \\right]$$\n",
    "\n",
    "\n",
    "where $A = 10$, $x_i ∈ [-5.12, 5.12]$\n",
    "\n",
    "Global Minimum : $f(x) = 0$ for $x = 0$\n",
    "\n",
    "Maximum Function Value: $xi ∈ [±4.52299366...,...,±4.52299366...]$\n",
    "\n",
    "#### code:\n",
    "\n",
    "```python\n",
    "\n",
    "def rastrigin(X):\n",
    "    if isinstance(X[0],(int,float)):\n",
    "        X = [[X[i]] for i in range(len(X))]\n",
    "    \n",
    "    val = []\n",
    "    for xi in X:\n",
    "        fx = 10 * len(xi) + sum(np.array(xi) ** 2 - 10 * np.cos(2 * np.pi * np.array(xi)))\n",
    "        val.append(fx)\n",
    "    return np.array(val)\n",
    "\n",
    "```\n",
    "\n",
    "### Population Generation\n",
    "\n",
    "The `generate_particle` function is responsible for initializing the swarm (population of particles) and their velocities.\n",
    "\n",
    "```python\n",
    "def generate_particle(num_variables, swarm_size, x_min, x_max):\n",
    "    swarm = np.random.uniform(x_min, x_max, (swarm_size, num_variables))\n",
    "    velocity = np.zeros_like(swarm)\n",
    "    return swarm, velocity\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "The `generate_particle` function initializes the swarm and their velocities as follows:\n",
    "\n",
    "1. **Swarm Initialization**:\n",
    "    - The swarm is a 2D array where each row represents a particle and each column represents a variable (dimension) of the problem.\n",
    "    - `np.random.uniform(x_min, x_max, (swarm_size, num_variables))` generates a swarm of particles with random positions. Each position is uniformly distributed between `x_min` and `x_max`.\n",
    "    - `swarm_size` specifies the number of particles in the swarm.\n",
    "    - `num_variables` specifies the number of dimensions (variables) for each particle.\n",
    "\n",
    "2. **Velocity Initialization**:\n",
    "    - The velocity is a 2D array of the same shape as the swarm.\n",
    "    - `np.zeros_like(swarm)` initializes the velocity of each particle to zero. This means that initially, particles have no movement.\n",
    "\n",
    "3. **Return Values**:\n",
    "    - The function returns the initialized `swarm` and `velocity`.\n",
    "\n",
    "## PSO Algorithms\n",
    "\n",
    "### 1. **PSO Algorithm 1**\n",
    "\n",
    "This is the first implementation of the PSO algorithm. It uses the following parameters:\n",
    "\n",
    "- **Number of Iterations:** 100\n",
    "- **Swarm Size:** 50\n",
    "- **Number of Variables:** 5\n",
    "- **Search Space:** [-5.12, 5.12]\n",
    "- **Inertia Weight (W):** 0.9\n",
    "- **Cognitive Coefficient (C1):** 0.2\n",
    "- **Social Coefficient (C2):** 0.7\n",
    "- **Velocity Coefficient (E):** 0.2\n",
    "\n",
    "#### code:\n",
    "\n",
    "```python\n",
    "def pso(num_iterations,swarm_size,num_variables,x_min,x_max,W,C1,C2,E):\n",
    "    swarm,velocity = generate_particle(num_variables,swarm_size,x_min,x_max)\n",
    "    local_best = np.copy(swarm)\n",
    "    global_best = np.full_like(local_best,local_best[index_finder(swarm)])\n",
    "    \n",
    "    for z in range(num_iterations):\n",
    "        swarm2 = swarm + (E * velocity)\n",
    "        swarm2 = np.clip(swarm2,x_min,x_max)\n",
    "        \n",
    "        ras_swarm = np.array(rastrigin(swarm))\n",
    "        ras_swarm2 = np.array(rastrigin(swarm2))\n",
    "        \n",
    "        for i in range(swarm_size):\n",
    "            if ras_swarm2[i] < ras_swarm[i]:\n",
    "                local_best[i] = swarm2[i]\n",
    "                continue\n",
    "            if min(ras_swarm2) < min(ras_swarm):\n",
    "                global_best = np.full_like(local_best,local_best[index_finder(swarm2)])\n",
    "                # print(global_best[0])\n",
    "                continue\n",
    "            \n",
    "        velocity = ((W*(W-.4)*velocity*z)/num_iterations) + C1 * np.random.uniform(0,1) * (local_best - swarm) + C2 * np.random.uniform(0,1) * (global_best - swarm)\n",
    "    \n",
    "    return global_best[0]\n",
    "```\n",
    "\n",
    "### 2. **PSO Algorithm 2**\n",
    "\n",
    "This is the second implementation of the PSO algorithm. It uses the following parameters:\n",
    "\n",
    "- **Number of Iterations:** 100\n",
    "- **Swarm Size:** 50\n",
    "- **Number of Variables:** 5\n",
    "- **Search Space:** [-5.12, 5.12]\n",
    "- **Inertia Weight (α):** 0.9  (controls the influence of the particle's previous velocity on its current velocity)\n",
    "- **Cognitive Coefficient (β):** 0.2 (controls the influence of the particle's own best-known position on its current velocity)\n",
    "- **Social Coefficient (γ):** 0.7 (controls the influence of the swarm's best-known position on the particle's current velocity)\n",
    "- **Velocity Coefficient (ε):** 0.2 (introduces stochasticity into the particle's movement)\n",
    "\n",
    "#### code:\n",
    "\n",
    "```python\n",
    "def pso1(num_iterations, swarm_size, num_variables, x_min, x_max, alpha, beta, gamma, epsilon):\n",
    "    \n",
    "    swarm, velocity = generate_particle(num_variables, swarm_size, x_min, x_max)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        swarm2 = swarm + epsilon * velocity\n",
    "        swarm2 = np.clip(swarm2,x_min,x_max)\n",
    "        \n",
    "        dicx = {tuple(swarm[i]): rastrigin(swarm)[i] for i in range(swarm_size)}\n",
    "        dicy = {tuple(swarm2[i]): rastrigin(swarm2)[i] for i in range(swarm_size)}\n",
    "\n",
    "        if i == 0:\n",
    "            \n",
    "            local_best = swarm\n",
    "            global_best = list(min(dicx, key=lambda k: dicx[k]))\n",
    "        else:\n",
    "            for j in range(swarm_size):\n",
    "                key1, value1 = list(dicx.items())[j]\n",
    "                key2, value2 = list(dicy.items())[j]\n",
    "                \n",
    "                local_best[j] = list(key2) if value2 < value1 else list(key1)\n",
    "                \n",
    "                global_best = list(min(dicy, key=lambda k: dicy[k])) if np.argmin(dicy) < np.argmin(dicx) else list(min(dicx, key=lambda k: dicx[k]))\n",
    "                      \n",
    "\n",
    "        velocity = (alpha * velocity + np.random.uniform(0, beta) * (np.array(local_best) - np.array(swarm)) + np.random.uniform(0, gamma) * (np.full_like(swarm, global_best) - np.array(swarm)))\n",
    "        \n",
    "        \n",
    "    return global_best\n",
    "```\n",
    "\n",
    "### 3. **PSO Algorithm 3**\n",
    "\n",
    "This is the third implementation of the PSO algorithm. It uses the following parameters:\n",
    "\n",
    "- **Number of Iterations:** 100\n",
    "- **Swarm Size:** 50\n",
    "- **Number of Variables:** 5\n",
    "- **Search Space:** [-5.12, 5.12]\n",
    "- **Inertia Weight (α):** 0.9  (controls the influence of the particle's previous velocity on its current velocity)\n",
    "- **Cognitive Coefficient (β):** 0.2 (controls the influence of the particle's own best-known position on its current velocity)\n",
    "- **Social Coefficient (γ):** 0.7 (controls the influence of the swarm's best-known position on the particle's current velocity)\n",
    "- **Velocity Coefficient (ε):** 0.2 (introduces stochasticity into the particle's movement)\n",
    "\n",
    "#### code:\n",
    "\n",
    "```python\n",
    "def pso2(num_iterations, swarm_size, num_variables, x_min, x_max, alpha, beta, gamma, epsilon):\n",
    "    def rastrigin(X):\n",
    "        return 10 * len(X) + sum([(x ** 2 - 10 * np.cos(2 * np.pi * x)) for x in X])\n",
    "\n",
    "    def generate_particle(num_variables, swarm_size, x_min, x_max):\n",
    "        swarm = np.random.uniform(x_min, x_max, (swarm_size, num_variables))\n",
    "        velocity = np.zeros_like(swarm)\n",
    "        return swarm, velocity\n",
    "\n",
    "    swarm, velocity = generate_particle(num_variables, swarm_size, x_min, x_max)\n",
    "    swarm = np.clip(swarm, x_min, x_max)\n",
    "    swarm_positions = [swarm.tolist()]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        swarm2 = swarm + epsilon * velocity\n",
    "        swarm2 = np.clip(swarm2, x_min, x_max)\n",
    "        \n",
    "        dicx = {tuple(swarm[i]): rastrigin(swarm[i]) for i in range(swarm_size)}\n",
    "        dicy = {tuple(swarm2[i]): rastrigin(swarm2[i]) for i in range(swarm_size)}\n",
    "\n",
    "        if i == 0:\n",
    "            local_best = swarm\n",
    "            global_best = list(min(dicx, key=dicx.get))\n",
    "        else:\n",
    "            for j in range(swarm_size):\n",
    "                key1, value1 = list(dicx.items())[j]\n",
    "                key2, value2 = list(dicy.items())[j]\n",
    "                \n",
    "                local_best[j] = list(key2) if value2 < value1 else list(key1)\n",
    "                \n",
    "                global_best = list(min(dicy, key=dicy.get)) if min(dicy.values()) < min(dicx.values()) else list(min(dicx, key=dicx.get))\n",
    "\n",
    "        velocity = (alpha * velocity + np.random.uniform(0, beta) * (np.array(local_best) - np.array(swarm)) + np.random.uniform(0, gamma) * (np.full_like(swarm, global_best) - np.array(swarm)))\n",
    "        \n",
    "        swarm = swarm2\n",
    "        swarm_positions.append(swarm.tolist())\n",
    "\n",
    "    return global_best, swarm_positions\n",
    "```\n",
    "\n",
    "The global best position found by this algorithm is:\n",
    "\n",
    "| Algorithm | Global Best Position | Rastrigin Function Value | Execution Time (s) |\n",
    "|-----------|----------------------|--------------------------|--------------------|\n",
    "| PSO 1     | [-0.12533879,  1.46136184, -1.89630133,  1.06640223,  0.19577871] | 39.13864322 | 21.2 |\n",
    "| PSO 2     | [-0.03599296788184522, -0.007506731239158595, 0.964353064235198, 0.02814849917431592, 0.026021897934319596] | 1.73769004 | 2.2 |\n",
    "| PSO 3     | [-1.9188176364182312, 0.019935083325026026, 5.12, -0.0008868580823031547, -0.01150699043412673] | 33.98469298 | 0.1 |\n",
    "\n",
    "## Simulation Demonstration\n",
    "\n",
    "Below is an animation demonstrating the simulation of the PSO algorithms:\n",
    "\n",
    "![PSO Simulation](pso_animation.gif)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In conclusion, all three PSO algorithms were able to find a global best position with similar Rastrigin function values. However, the specific positions found by each algorithm varied. This demonstrates the stochastic nature of the PSO algorithm and the importance of parameter tuning for achieving optimal results.\n",
    "\n",
    "## Comparative Study\n",
    "\n",
    "Complexity: All three algorithms have similar computational complexity, primarily $(O(n \\cdot m \\cdot k))$, where (n) is the number of iterations, (m) is the swarm size, and (k) is the number of variables.\n",
    "\n",
    "Convergence: PSO Algorithm 2 showed the best convergence to the global minimum with the lowest Rastrigin function value. This suggests that the specific parameter tuning in Algorithm 2 was more effective for this problem.\n",
    "\n",
    "Stability: The results indicate that Algorithm 2 is more stable and consistent in finding a better solution compared to Algorithms 1 and 3.\n",
    "\n",
    "Exploration vs. Exploitation: The parameters in Algorithm 2 provided a better balance between exploration (searching new areas) and exploitation (refining known good areas), leading to better overall performance.\n",
    "\n",
    "**Note:** The animation file is attached to provide a visual demonstration of the PSO algorithms in 2-variables.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
